-- LOADING DATA FROM AMAZON S3 TO SNOWFLAKE DATAWAREHOUSE THROUGH EXTERNAL STAGE


CREATE STORAGE INTEGRATION my_s3_integration
  TYPE = EXTERNAL_STAGE
  STORAGE_PROVIDER = S3
  ENABLED = TRUE
  STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::538702124322:role/snow_4092'
  STORAGE_ALLOWED_LOCATIONS = ('s3://consumercompl4092/consumer4092/');

  desc integration my_s3_integration;

  -- Create an External Stage
CREATE STAGE my_s3_stage
  URL = 's3://consumercompl4092/consumer4092/'
  STORAGE_INTEGRATION = my_s3_integration;


  -- list object in stage
  ls @my_s3_stage;


  -- Example of using the Storage Integration to copy data from S3 into a Snowflake table
COPY INTO CONSUM_COMPLAINTS_AWS
FROM @my_s3_stage
FILE_FORMAT = my_csv_format;



--Step 3: Create a File Format:

--If your data files are in a format other than CSV (e.g., JSON, Parquet, etc.), you'll need to create a file format that matches the file type.
CREATE FILE FORMAT my_csv_format
  TYPE = CSV
  FIELD_DELIMITER = ','
  RECORD_DELIMITER = '\n'
  SKIP_HEADER = 1; -- Set to 0 if your file doesn't have a header row
  

select * from CONSUM_COMPLAINTS_AWS limit 10;
select count(*) from CONSUM_COMPLAINTS_AWS;
